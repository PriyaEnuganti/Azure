{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHN_KE1awnoX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "    print(\"Device:\", tpu.master())\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFC_-wtnwnoY"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 25 * strategy.num_replicas_in_sync\n",
        "IMAGE_SIZE = [180, 180]\n",
        "CLASS_NAMES = [\"NORMAL\", \"PNEUMONIA\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qROv8FaRwnoY"
      },
      "source": [
        "## Load the data\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0pKioYvwnoY"
      },
      "outputs": [],
      "source": [
        "train_images = tf.data.TFRecordDataset(\n",
        "    \"gs://download.tensorflow.org/data/ChestXRay2017/train/images.tfrec\"\n",
        ")\n",
        "train_paths = tf.data.TFRecordDataset(\n",
        "    \"gs://download.tensorflow.org/data/ChestXRay2017/train/paths.tfrec\"\n",
        ")\n",
        "\n",
        "ds = tf.data.Dataset.zip((train_images, train_paths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j53mAqmFwnoZ"
      },
      "source": [
        "Let's count how many healthy/normal chest X-rays we have and how many\n",
        "pneumonia chest X-rays we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkinntAiwnoZ"
      },
      "outputs": [],
      "source": [
        "COUNT_NORMAL = len(\n",
        "    [\n",
        "        filename\n",
        "        for filename in train_paths\n",
        "        if \"NORMAL\" in filename.numpy().decode(\"utf-8\")\n",
        "    ]\n",
        ")\n",
        "print(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n",
        "\n",
        "COUNT_PNEUMONIA = len(\n",
        "    [\n",
        "        filename\n",
        "        for filename in train_paths\n",
        "        if \"PNEUMONIA\" in filename.numpy().decode(\"utf-8\")\n",
        "    ]\n",
        ")\n",
        "print(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8pUHmnwwnoZ"
      },
      "source": [
        "  There are way more images that are classified as pneumonia than normal. This\n",
        "shows that we have an imbalance in our data. We will correct for this imbalance later on\n",
        "in our notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mnIeA0nwnoZ"
      },
      "source": [
        "We want to map each filename to the corresponding (image, label) pair. The following\n",
        "methods will help us do that.\n",
        "\n",
        "As we only have two labels, we will encode the label so that `1` or `True` indicates\n",
        "pneumonia and `0` or `False` indicates normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP8UiirLwnoZ"
      },
      "outputs": [],
      "source": [
        "def get_label(file_path):\n",
        "    # convert the path to a list of path components\n",
        "    parts = tf.strings.split(file_path, \"/\")\n",
        "    # The second to last is the class-directory\n",
        "    if parts[-2] == \"PNEUMONIA\":\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def decode_img(img):\n",
        "    # convert the compressed string to a 3D uint8 tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    # resize the image to the desired size.\n",
        "    return tf.image.resize(img, IMAGE_SIZE)\n",
        "\n",
        "\n",
        "def process_path(image, path):\n",
        "    label = get_label(path)\n",
        "    # load the raw data from the file as a string\n",
        "    img = decode_img(image)\n",
        "    return img, label\n",
        "\n",
        "\n",
        "ds = ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFMA339PwnoZ"
      },
      "source": [
        "Let's split the data into a training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1JdtQY6wnoZ"
      },
      "outputs": [],
      "source": [
        "ds = ds.shuffle(10000)\n",
        "train_ds = ds.take(4200)\n",
        "val_ds = ds.skip(4200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9TbOfVSwnoa"
      },
      "source": [
        "Let's visualize the shape of an (image, label) pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y34UXjmwnoa"
      },
      "outputs": [],
      "source": [
        "for image, label in train_ds.take(1):\n",
        "    print(\"Image shape: \", image.numpy().shape)\n",
        "    print(\"Label: \", label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ORISwC2wnoa"
      },
      "source": [
        "Load and format the test data as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAslPezKwnoa"
      },
      "outputs": [],
      "source": [
        "test_images = tf.data.TFRecordDataset(\n",
        "    \"gs://download.tensorflow.org/data/ChestXRay2017/test/images.tfrec\"\n",
        ")\n",
        "test_paths = tf.data.TFRecordDataset(\n",
        "    \"gs://download.tensorflow.org/data/ChestXRay2017/test/paths.tfrec\"\n",
        ")\n",
        "test_ds = tf.data.Dataset.zip((test_images, test_paths))\n",
        "\n",
        "test_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFAg-5_ywnoa"
      },
      "source": [
        "## Visualize the dataset\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MuolHhIwnoa"
      },
      "outputs": [],
      "source": [
        "def prepare_for_training(ds, cache=True):\n",
        "    # This is a small dataset, only load it once, and keep it in memory.\n",
        "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "    # fit in memory.\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "    # is training.\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1ATMWbownoa"
      },
      "source": [
        "Call the next batch iteration of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcHLDbptwnoa"
      },
      "outputs": [],
      "source": [
        "train_ds = prepare_for_training(train_ds)\n",
        "val_ds = prepare_for_training(val_ds)\n",
        "\n",
        "image_batch, label_batch = next(iter(train_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUb6Jryhwnoa"
      },
      "source": [
        "Define the method to show the images in the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d22GBw_Ewnoa"
      },
      "outputs": [],
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for n in range(25):\n",
        "        ax = plt.subplot(5, 5, n + 1)\n",
        "        plt.imshow(image_batch[n] / 255)\n",
        "        if label_batch[n]:\n",
        "            plt.title(\"PNEUMONIA\")\n",
        "        else:\n",
        "            plt.title(\"NORMAL\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8RtyGcLwnoa"
      },
      "outputs": [],
      "source": [
        "show_batch(image_batch.numpy(), label_batch.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SML7jC96wnoa"
      },
      "source": [
        "## Build the CNN\n",
        "\n",
        "\n",
        " building a convolution neural network, will create a convolution block and a dense\n",
        "layer block.\n",
        "\n",
        "The architecture for this CNN has been inspired by this\n",
        "[article](https://towardsdatascience.com/deep-learning-for-detecting-pneumonia-from-x-ray-images-fc9a3d9fdba8)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hXSl9s9wnoa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "def conv_block(filters, inputs):\n",
        "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.MaxPool2D()(x)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def dense_block(units, dropout_rate, inputs):\n",
        "    x = layers.Dense(units, activation=\"relu\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhka_VQdwnoa"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "\n",
        "    x = conv_block(32, x)\n",
        "    x = conv_block(64, x)\n",
        "\n",
        "    x = conv_block(128, x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = conv_block(256, x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = dense_block(512, 0.7, x)\n",
        "    x = dense_block(128, 0.5, x)\n",
        "    x = dense_block(64, 0.3, x)\n",
        "\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KQDBTyKwnoa"
      },
      "source": [
        "## Correct for data imbalance\n",
        "As the data was imbalanced, with more images classified\n",
        "as pneumonia than normal. We will correct for that by using class weighting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQtQczAywnob"
      },
      "outputs": [],
      "source": [
        "initial_bias = np.log([COUNT_PNEUMONIA / COUNT_NORMAL])\n",
        "print(\"Initial bias: {:.5f}\".format(initial_bias[0]))\n",
        "\n",
        "TRAIN_IMG_COUNT = COUNT_NORMAL + COUNT_PNEUMONIA\n",
        "weight_for_0 = (1 / COUNT_NORMAL) * (TRAIN_IMG_COUNT) / 2.0\n",
        "weight_for_1 = (1 / COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) / 2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print(\"Weight for class 0: {:.2f}\".format(weight_for_0))\n",
        "print(\"Weight for class 1: {:.2f}\".format(weight_for_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bqUF13iwnob"
      },
      "source": [
        "The weight for class `0` (Normal) is a lot higher than the weight for class `1`\n",
        "(Pneumonia). Because there are less normal images, each normal image will be weighted\n",
        "more to balance the data as the CNN works best when the training data is balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i37V4iLwnob"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS5lY5chwnob"
      },
      "source": [
        "### Defining callbacks\n",
        "\n",
        "The checkpoint callback saves the best weights of the model, so next time we want to use\n",
        "the model, we do not have to spend time training it. The early stopping callback stops\n",
        "the training process when the model starts becoming stagnant, or even worse, when the\n",
        "model starts overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRvz6NVLwnob"
      },
      "outputs": [],
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"xray_model.keras\", save_best_only=True)\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
        "    patience=10, restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik2rtG82wnob"
      },
      "source": [
        "We also want to tune our learning rate. Too high of a learning rate will cause the model\n",
        "to diverge. Too small of a learning rate will cause the model to be too slow. We\n",
        "implement the exponential learning rate scheduling method below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps8Lipp9wnob"
      },
      "outputs": [],
      "source": [
        "initial_learning_rate = 0.015\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aATmk6Cwnob"
      },
      "source": [
        "### Fit the model\n",
        "\n",
        "For our metrics, we want to include precision and recall as they will provide use with a\n",
        "more informed picture of how good our model is. Accuracy tells us what fraction of the\n",
        "labels is correct. Since our data is not balanced, accuracy might give a skewed sense of\n",
        "a good model (i.e. a model that always predicts PNEUMONIA will be 74% accurate but is not\n",
        "a good model).\n",
        "\n",
        "Precision is the number of true positives (TP) over the sum of TP and false positives\n",
        "(FP). It shows what fraction of labeled positives are actually correct.\n",
        "\n",
        "Recall is the number of TP over the sum of TP and false negatves (FN). It shows what\n",
        "fraction of actual positives are correct.\n",
        "\n",
        "Since there are only two possible labels for the image, we will be using the\n",
        "binary crossentropy loss. When we fit the model, remember to specify the class weights,\n",
        "which we defined earlier. Because we are using a TPU, training will be quick - less than\n",
        "2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6_j0R1-wnok"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    model = build_model()\n",
        "\n",
        "    METRICS = [\n",
        "        keras.metrics.BinaryAccuracy(),\n",
        "        keras.metrics.Precision(name=\"precision\"),\n",
        "        keras.metrics.Recall(name=\"recall\"),\n",
        "    ]\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=METRICS,\n",
        "    )\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=100,\n",
        "    validation_data=val_ds,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDvr27XBwnok"
      },
      "source": [
        "## Visualizing model performance\n",
        "\n",
        " Next is top plot the model accuracy and loss for the training and the validating set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXDy1RwIwnok"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate([\"precision\", \"recall\", \"binary_accuracy\", \"loss\"]):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history[\"val_\" + met])\n",
        "    ax[i].set_title(\"Model {}\".format(met))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGCY3QJcwnok"
      },
      "source": [
        "## Predict and evaluate results\n",
        "\n",
        "Let's evaluate the model on our test data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRiXFsQXwnok"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcQHE0y2wnok"
      },
      "outputs": [],
      "source": [
        "for image, label in test_ds.take(1):\n",
        "    plt.imshow(image[0] / 255.0)\n",
        "    plt.title(CLASS_NAMES[label[0].numpy()])\n",
        "\n",
        "prediction = model.predict(test_ds.take(1))[0]\n",
        "scores = [1 - prediction, prediction]\n",
        "\n",
        "for score, name in zip(scores, CLASS_NAMES):\n",
        "    print(\"This image is %.2f percent %s\" % ((100 * score), name))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "xray_classification_with_tpus",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}